# -*- coding: utf-8 -*-
"""SMT_Tutorial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13Qy6YHWJYx2osAdr0Bv3b4XgX2Nr57IT

<a href="https://colab.research.google.com/github/SMTorg/smt/blob/master/tutorial/SMT_Tutorial.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

<div class="jumbotron text-left"><b>
This tutorial describes how to use the SMT toolbox, which is a python toolbox for building a surrogate model.</b></div>

Nathalie BARTOLI ONERA/DTIS/M2CI - May 2024

based on `SMT 2.5.1 version`

<div class="alert alert-info fade in" id="d110">
<p>Latest updates</p>
<ol> - sparse gaussian process for large database </ol>
<ol> - use GPX build in Rust in order to reduce time for trining and prediction (KRG or KPLS models) </ol>
    
 <p>Previous updates</p>  
<ol>     -correct the figures with matplotlib:  ax =  fig.add_subplot(projection='3d') </ol>
<ol> - prediction and variance derivatives for different kernels (squared exponential, absolute exponential, matern 32, matern 52) and trends (constant, linear) </ol>
<ol> -  Kriging with integer variables </ol>   
<ol> -  compare different covariance kernels for the kriging models </ol>
<ol> -  automatic choice of PLS comonents </ol>
<ol> -  example to use Marginal Gaussian Process   </ol>    
<ol> -  example to use multiple outputs (independant outputs) </ol>
<ol> -  example to compare models using Mixture of experts technique  </ol>  
<ol> -  example to save and load models using  `pickle`  </ol>    

</div>

<p class="alert alert-success" style="padding:1em">
To use SMT models, please follow this link : https://github.com/SMTorg/SMT/blob/master/README.md. The documentation is available here: http://smt.readthedocs.io/en/latest/
</p>

The reference paper is available
here https://www.sciencedirect.com/science/article/pii/S0965997818309360?via%3Dihub

or as a preprint: https://www.researchgate.net/profile/Mohamed_Amine_Bouhlel/publication/331976718_A_Python_surrogate_modeling_framework_with_derivatives/links/5cc3cebd299bf12097829631/A-Python-surrogate-modeling-framework-with-derivatives.pdf

Cite us:

M.-A. Bouhlel, J. T. Hwang, N. Bartoli, R. Lafage, J. Morlier, J .R.R.A Martins (2019), A Python surrogate modeling framework with derivatives, Advances in Engineering Software, 102662

P. Saves, R. Lafage, N. Bartoli, Y. Diouane, J. Bussemaker, T. Lefebvre, J. T. Hwang, J. Morlier, J. RRA. Martins (2024). SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes. Advances in Engineering Software, 188, 103571.

@article{SMT2019,
  title={A Python surrogate modeling framework with derivatives},
  author={Mohamed Amine Bouhlel and John T. Hwang and Nathalie Bartoli and R{\'e}mi Lafage and Joseph Morlier and Joaquim R. R. A. Martins},
  journal={Advances in Engineering Software},
  pages={102662},
  year={2019},
  publisher={Elsevier}
}

@article{saves2024smt,
  title={SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes},
  author={Saves, Paul and Lafage, R{\'e}mi and Bartoli, Nathalie and Diouane, Youssef and Bussemaker, Jasper and Lefebvre, Thierry and Hwang, John T and Morlier, Joseph and Martins, Joaquim RRA},
  journal={Advances in Engineering Software},
  volume={188},
  pages={103571},
  year={2024},
  publisher={Elsevier}
}

<div class="alert alert-danger" >
<p> In most of the surrogate models $y\in\mathbb{R}$, so if you have multiple outputs $y\in\mathbb{R}^d$ (which are considered as independant outputs), add an external loop to build one surrogate model per output. The correlations betweens outputs are not taken into account. Section 11 of this notebook presents an example with 2 outputs.
</div>

<div class="alert alert-warning" >
In this notebook, the database is considered to be noise-free. If you want to consider noisy data, please have a look at the dedicated notebook available within SMT.
</div>
"""

from __future__ import print_function, division

# !pip install smt
# # to reduce CPU time
# !pip install numba

"""<div class="alert alert-warning" >
If you use hierarchical variables and the size of your doe greater than 30 points, you may leverage the `numba` JIT compiler to speed up the computation
To do so:
    
 - install numba library
    
     `pip install numba`
    
    
 - and define the environment variable `USE_NUMBA_JIT = 1` (unset or 0 if you do not want to use numba)
    
     - Linux: export USE_NUMBA_JIT = 1
    
     - Windows: set USE_NUMBA_JIT = 1

</div>
"""

# # to check if numba is available
# !pip show numba
# # and then you need to define the environment variable USE_NUMBA_JIT
# !echo "Numba used or not in your environment=" %USE_NUMBA_JIT%

"""# 0. Construction of the DOE points"""

import numpy as np
import torch
from torch import nn
import matplotlib.pyplot as plt
from torchinfo import summary


def Rosenbrock(x, n):
    value = 0
    for i in range(0,2):
        value += 100 * (x[i+1] - x[i]**2)**2 + (1 - x[i])**2

    return value
def Rosenbrock1(x, n):
    value = 0
    for i in range(3,4):
        value += 100 * (x[i+1] - x[i]**2)**2 + (1 - x[i])**2

    return value
def dixon_price(x):
    n = len(x)
    term1 = (x[0] - 1) ** 2
    term2 = sum([i * (2 * x[i]**2 - x[i-1])**2 for i in range(1, n)])
    return term1 + term2

def powell(x):
    n = len(x)
    if n % 4 != 0:
        raise ValueError("Input vector length must be a multiple of 4.")
    
    sum_term = 0
    for i in range(0, n, 4):
        term1 = (x[i] + 10 * x[i+1]) ** 2
        term2 = 5 * (x[i+2] - x[i+3]) ** 2
        term3 = (x[i+1] - 2 * x[i+2]) ** 4
        term4 = 10 * (x[i] - x[i+3]) ** 4
        sum_term += term1 + term2 + term3 + term4
    
    return sum_term
def objective_function(x,dim):
    tmp1 = Rosenbrock(x,dim)
    tmp2 = Rosenbrock1(x,dim)
    return tmp1+tmp2
    # n_rosenbrock = 3
    # n_dixon=3
    # n_powell=4
    # rosen_value = Rosenbrock(x[:n_rosenbrock], n_rosenbrock)
    # dixon_value = dixon_price(x[n_rosenbrock:n_rosenbrock+n_dixon])
    # powell_value= powell(x[n_rosenbrock+n_dixon:n_rosenbrock+n_dixon+n_powell])
    # return rosen_value + dixon_value+ powell_value

# パラメータの設定
dim = 6
max_gen = 10
pop_size = 20
offspring_size = 300
bound = 5
from datetime import datetime

# 現在の時刻を取得
current_time = datetime.now()
name = f'{current_time}_{pop_size}'



# 初期集団の生成
def init_population(pop_size, dim, bound):
    return [np.random.uniform(-bound, bound, dim) for _ in range(pop_size)]

# 適合度の計算
def evaluate_population(population):
    # return objective_function(population,dim)
    return [objective_function(individual, dim) for individual in population]

def genetic_algorithm(dim, max_gen, pop_size, offspring_size, bound):
    population = init_population(pop_size, dim, bound)
    for generation in range(max_gen):
        fitness = evaluate_population(population)
        # print(generation,population,fitness)
    return population, fitness



# 実行

import numpy as np
from smt.utils.misc import compute_rms_error

# from smt.problems import Rosenbrock
from smt.sampling_methods import LHS
from smt.surrogate_models import LS, QP, KPLS, KRG, KPLSK, GEKPLS, MGP

try:
    from smt.surrogate_models import IDW, RBF, RMTC, RMTB

    compiled_available = True
except Exception:
    compiled_available = False

try:
    import matplotlib.pyplot as plt

    plot_status = True
except Exception:
    plot_status = False


import matplotlib.pyplot as plt
from matplotlib import cm


# to ignore warning messages
import warnings

warnings.filterwarnings("ignore")

from datetime import datetime
import os 
# 現在の時刻を取得
current_time = datetime.now()
name = f'{current_time}'
# 保存するディレクトリを作成
if not os.path.exists(name):
    os.makedirs(name)
def dirs():
    return name
# ファイルのパスを指定
file_path = os.path.join(name, "population.txt")
file_path2 = os.path.join(name,"weight.txt")
file_path3 = os.path.join(name,"matrix.txt")

def make_file_path():
    return file_path


"""## Rosenbrock Function  in dimension N

$$
f(\mathbf{x}) = \sum_{i=1}^{N-1} 100 (x_{i+1} - x_i^2 )^2 + (1-x_i)^2 \quad \mbox{where} \quad \mathbf{x} = [x_1, \ldots, x_N] \in \mathbb{R}^N.
$$

$$x_i \in [-2,2]$$

## Training points and validation points using a LHS algorithm

Here we outline the studied function by plotting the surface representing the function. In addition, we plot also the training points used later to build the surrogate model as well as the validation points which will be used to evaluate the quality of the surrogate model. Both the training point and validation points are generated by a LHS DOE algorithm.

<div class="alert alert-danger" >
<p> In order to have reproducibility of the tests and results, we use  the option random_state to set a seed to the random generator, so that your DOE points are always deterministic. If you don't set a seed, it is different each time.
</div>
"""

########### Initialization of the problem, construction of the training and validation points

ndim = dim
ndoe = pop_size  # int(10*ndim)


# population, fitness = genetic_algorithm(dim, max_gen, pop_size, offspring_size, bound)

# xt = [arr.tolist() for arr in population]
# # Compute the outputs
# yt = [arr.tolist() for arr in fitness]
# with open(file_path, "a") as file:
#         file.write(f"{xt},{yt}\n")
# xt =  [[xt[i], xt[i + 1]] for i in range(0, len(xt), 2)]
# yt = [[yt[i], yt[i + 1]] for i in range(0, len(yt), 2)]

population, fitness = genetic_algorithm(dim, max_gen, pop_size, offspring_size, bound)



xt = np.array(population, dtype=np.double)    
yt = np.array(fitness, dtype=np.double)
yt=yt.reshape(20,1)
# Construction of the validation points
ntest = 200  # 500

population_test, fitness_test = genetic_algorithm(dim, max_gen, pop_size, offspring_size, bound)

def QOL():
    population_test, fitness_test = genetic_algorithm(dim, max_gen, pop_size, offspring_size, bound)
    return population_test,fitness_test


xtest = np.array(population_test, dtype=np.double)    
ytest = np.array(fitness_test, dtype=np.double)
ytest=ytest.reshape(20,1)


# xtest = [arr.tolist() for arr in population_test]
# # Compute the outputs
# ytest = [arr.tolist() for arr in fitness_test]


"""Different models will be used and compared:

- Linear Model (first order polynomial)
- Quadratic Model (second order polynomial)
- Kriging Model (also known as Gaussian Process)
- KPLS Model and KPLSK Model (useful for Kriging in high dimension)
- IDW Model (Inverse Distance Weighting)
- RBF Model (Radial Basis Function)
- RMTS Models: RMTB and RMTC (useful for low dimensional problem)

Some metrics to assess some errors are proposed at the end.

Mixture of experts technique will be used to compare different surrogate models.

"""

"""# 6. RBF Model
Here we implement the RBF model.
"""


def get_xt():
    return xt

def xt_all():
    return xt
def get_yt():
    return yt
tmp = yt[0]


########### The RBF model

t = RBF(print_prediction=False, poly_degree=0)

t.set_training_values(xt, yt)

t.train()
with open(file_path, "a") as file:
    file.write(f"{xt}\n")
with open(file_path2, "a") as file:
    file.write(f"{t.sol}\n")
with open(file_path3, "a") as file:
    file.write(f"{t.mtx}\n")
def matrix():
    return t.mtx.tolist()
def weight():

    return t.sol


# Prediction of the validation points
y = t.predict_values(xtest)
print("RBF,  err: " + str(compute_rms_error(t, xtest, ytest)))
# Plot prediction/true values
if plot_status:
    fig = plt.figure()
    plt.plot(ytest, ytest, "-", label="$y_{true}$")
    plt.plot(ytest, y, "r.", label=r"$\hat{y}$")

    plt.xlabel("$y_{true}$")
    plt.ylabel(r"$\hat{y}$")

    plt.legend(loc="upper left")
    plt.title("RBF model: validation of the prediction model")
    plt.savefig('RBF model: validation of the prediction model.png')
def t_preditct(xtest):
    return t.predict_values(xtest)
